{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIfEYEoyLUI2"
   },
   "source": [
    "## Use of Dropout and Batch Normalization in 2D CNN on Dog Cat Image Classification in TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISD_RncZLUI4"
   },
   "source": [
    "## What is Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MeYhGe2ovuOJ"
   },
   "source": [
    "Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gFBkdG-vuSX"
   },
   "source": [
    "![alt text](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/drop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygUfjZWlLUI5"
   },
   "source": [
    "# What is Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx-_XtL00upZ"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/935/1*4T4y3kI0R9Alk_2pe6B4Pg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9b4qTn6vvEi"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/886/1*WRio7MD4JDeLww-CyrxEbg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hotIuo4t0Fcr"
   },
   "source": [
    "Normalization brings all the inputs centered around 0. This way, there is not much change in each layer input. So, layers in the network can learn from the back-propagation simultaneously, without waiting for the previous layer to learn. This fastens up the training of networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9eHd1WF4RNf"
   },
   "source": [
    "<img src = \"https://miro.medium.com/max/3840/1*oB3S5yHHhvougJkPXuc8og.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLVRyBl63EQs"
   },
   "source": [
    "# VGG16 Model\n",
    "\n",
    "![alt text](https://qph.fs.quoracdn.net/main-qimg-e657c195fc2696c7d5fc0b1e3682fde6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f431WjbELUJF"
   },
   "source": [
    "## Download Data from GitHub and Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "j6jXjvslL5NR",
    "outputId": "9073fc8d-be7e-48b0-fdce-fefc19771b49"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.0.0-rc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IObZyy51LUJG",
    "outputId": "82ca5c8e-8253-42be-d67c-12dd27848eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, ZeroPadding2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(tf.__version__)\n",
    "# https://github.com/laxmimerit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfIV-gJtLUJK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "QttZI-n_29ln",
    "outputId": "a0c38a5b-8cd9-4920-d619-f663ec10cfbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dog-cat-full-dataset'...\n",
      "remote: Enumerating objects: 25027, done.\u001b[K\n",
      "remote: Counting objects: 100% (25027/25027), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25022/25022), done.\u001b[K\n",
      "Receiving objects:  29% (7281/25027), 153.13 MiB | 1.43 MiB/s      \r"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/laxmimerit/dog-cat-full-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuGY7n79zlj5"
   },
   "outputs": [],
   "source": [
    "test_data_dir = '/content/dog-cat-full-dataset/data/test'\n",
    "train_data_dir = '/content/dog-cat-full-dataset/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yJOPI8l_bg5"
   },
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZjYS01o_bjg"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eNZOge60_bmD",
    "outputId": "b78ec442-9414-48cb-ea02-0a60c9ee6389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(directory=train_data_dir,\n",
    "                                              target_size = (img_width, img_height),\n",
    "                                              classes = ['dogs', 'cats'],\n",
    "                                              class_mode = 'binary',\n",
    "                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "I_uKCKwq_brF",
    "outputId": "9effccb0-5f38-4fd7-8fde-5933a96aa7cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "elUbsA7u_btb",
    "outputId": "24c40977-7937-4779-fc87-dc40bed202af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(directory=test_data_dir,\n",
    "                                                   target_size = (32, 32),\n",
    "                                                   classes = ['dogs', 'cats'],\n",
    "                                                   class_mode = 'binary',\n",
    "                                                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PxOFQpvB_bv5",
    "outputId": "94403e2e-4b94-4137-fe5d-298ebecef38c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmNP-MTe_byg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ovx8-TBEfqA"
   },
   "source": [
    "## Build CNN Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzdnTduQ_b1D"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform', input_shape = (img_width, img_height, 3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ii9qiSRP_b3q"
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "WUWOw2E7_b6g",
    "outputId": "eea45151-5de4-4b7d-e50e-6c8bd3d2b5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      " 665/1000 [==================>...........] - ETA: 32s - loss: 0.6955 - accuracy: 0.5134"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=len(train_generator), epochs = 5, validation_data=validation_generator, validation_steps=len(validation_generator), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3Z5mqRT_b_R"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CacbomNQ_cB7"
   },
   "outputs": [],
   "source": [
    "def plot_learningCurve(history):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, 6)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OE_uWHtf_cEy"
   },
   "outputs": [],
   "source": [
    "plot_learningCurve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diE0Wsa1_cHV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aghH0Tv2Jiup"
   },
   "source": [
    "## Impliment First 3 Blocks of VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G-u0b0CJu1p"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform', input_shape = (img_width, img_height, 3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hygOXtv1Ju10"
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhCo2uXvJu14"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=len(train_generator), epochs = 5, validation_data=validation_generator, validation_steps=len(validation_generator), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYQ3UaQC_cOa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_I9vxZWZ_cRb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDTTc-9J_cUC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JxmtPHKOpBr"
   },
   "source": [
    "## Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVpP9qUf_cZT"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform', input_shape = (img_width, img_height, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXUs8nOL_cW5"
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsxjR_Xq_cKg"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=len(train_generator), epochs = 10, validation_data=validation_generator, validation_steps=len(validation_generator), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7V19CDeQ_b9w"
   },
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epoch+1)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljryaDDB_boi"
   },
   "outputs": [],
   "source": [
    "plot_learningCurve(history, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1zFEePdzlYd"
   },
   "outputs": [],
   "source": [
    ">>> from itertools import groupby\n",
    ">>> from operator import itemgetter\n",
    ">>> data = [ 1, 4,5,6, 10, 15,16,17,18, 22, 25,26,27,28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 6, 10, 15, 16, 17, 18, 22, 25, 26, 27, 28]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e6dbd05c54a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "for k, g in groupby(enumerate(data), lambda i, x: i-x):\n",
    "    print (map(itemgetter(1), g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [100, 4, 2, 1,10, 3] \n",
    "l1 = [1,20,3,4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 10, 100]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_lsit(l):\n",
    "    for i in range(len(l)):\n",
    "        for j in range(0, len(l) -i -1):\n",
    "            if(l[j] > l [j+1]):\n",
    "                l[j] , l [j+1] = l[j+1], l[j]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 20]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_lsit(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "A = [1,3,4,5,3,1,4]\n",
    "l3 = []\n",
    "l4 = []\n",
    "val = 0\n",
    "\n",
    "for i in A:\n",
    "    if i not in l3:\n",
    "        l3.append(i)\n",
    "    else:\n",
    "        l4.append(i)\n",
    "        \n",
    "for j in l3:\n",
    "    if j not in l4:\n",
    "        val = j\n",
    "    \n",
    "print(val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupSequence(lst): \n",
    "    res = [[lst[0]]] \n",
    "  \n",
    "    for i in range(1, len(lst)): \n",
    "        if lst[i-1]+1 == lst[i]: \n",
    "            res[-1].append(lst[i]) \n",
    "  \n",
    "        else: \n",
    "            res.append([lst[i]]) \n",
    "    return res \n",
    "      \n",
    "# Driver program  \n",
    "l = [8, 9, 10, 7,11, 8, 1, 2, 3] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [20], [100]]\n"
     ]
    }
   ],
   "source": [
    "l2 = [1,100,2, 4,3, 20]\n",
    "\n",
    "l1 = sorted(l2)\n",
    "l3 = print(groupSequence(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [8, 1, 100, 4, 3, 2]\n",
    "A = sorted(A)\n",
    "length = len(A)\n",
    "\n",
    "l5 = []\n",
    "for j in range(length):\n",
    "    if(j +1 < length):\n",
    "        if (A[j] + 1 == A[j + 1] ):\n",
    "            l5.append(j)\n",
    "              \n",
    "val = len(l5) + 1\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = len(l5) + 1\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (1)\n",
    "t1 = t +10\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "TensorFlow 2.0 Tutorial for Beginners - Use of Dropout and Batch Normalization in 2D CNN on Dog Cat Image Classification in TensorFlow 2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
