{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "from collections import Counter , defaultdict\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get only duplicate value :  [1, 1, 2, 2]\n",
      "all unique value         :  [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "from iteration_utilities import duplicates, unique_everseen\n",
    "\n",
    "print(\"get only duplicate value : \", list(duplicates([1,1,2,1,2,3,4,2])))\n",
    "\n",
    "print(\"all unique value         : \", list(unique_everseen([1,1,2,1,2,3,4,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute for missing value(Numberical : mean, categorical :mode(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0] if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['a', 1, 2],\n",
    "    ['b', 1, 1],\n",
    "    ['b', 2, 2],\n",
    "    [np.nan, np.nan, np.nan]]\n",
    "\n",
    "df5 = pd.DataFrame(data , columns=[\"A\", \"B\", \"C\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Raka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rakesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Raka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C       D\n",
       "0    a  1.0  2.0    Raka\n",
       "1    b  1.0  1.0  rakesh\n",
       "2    b  2.0  2.0    Raka\n",
       "3  NaN  NaN  NaN     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.loc[:,\"D\"] = [\"Raka\" ,\"rakesh\", \"Raka\", np.nan]\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Raka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>rakesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Raka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>Raka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A         B         C       D\n",
       "0  a  1.000000  2.000000    Raka\n",
       "1  b  1.000000  1.000000  rakesh\n",
       "2  b  2.000000  2.000000    Raka\n",
       "3  b  1.333333  1.666667    Raka"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = DataFrameImputer().fit_transform(df5)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "def remove_outlier(dataframe):\n",
    "    low = .05\n",
    "    high = .95\n",
    "    quant_df = dataframe.quantile([low, high])\n",
    "    for name in list(dataframe.columns):\n",
    "        if is_numeric_dtype(dataframe[name]):\n",
    "            dataframe = dataframe[(dataframe[name] > quant_df.loc[low, name]) & (dataframe[name] < quant_df.loc[high, name])]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>name0</td>\n",
       "      <td>address0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>name1</td>\n",
       "      <td>address1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   name   address\n",
       "0   71  name0  address0\n",
       "1   34  name1  address1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\timport numpy as np\n",
    "\tfrom pandas.api.types import is_numeric_dtype\n",
    "\tnp.random.seed(42)\n",
    "\tage = np.random.randint(20,100,50)\n",
    "\tname = ['name'+str(i) for i in range(50)]\n",
    "\taddress = ['address'+str(i) for i in range(50)]\n",
    "\tdf1 = pd.DataFrame(data={'age':age, 'name':name, 'address':address})\n",
    "\tdf1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "t1 = [.01, 24, 81, 70, 30, 74, 24, 63, 82, 31, 12, 81, 29, 17, 31, 80, 29, 10, 82, 15, 17, 0.01, \n",
    "      28, 68, 91, 19, 9, 24, 111, 11, 26, 11, 40, 94, 23, 12, 30, 16, 20, 72, 98, 17, 23, 19, 73, 88, \n",
    "      92, 81, 69, 39]\n",
    "\n",
    "t2 = [114, 9908, 191, 801, 1140, 941, 194, 4113, 22, 1111, 1172, 212, 4229, 257, 221, 2283, 79, 4022, 52,\n",
    "      295, 727, 21, \n",
    "      628, 7118, 611, 719, 991, 341, 811, 831, 616, 815, 709, 754, 8663, 252, 750, 526, 480, 292, 598, 337,\n",
    "      233, 739, 333, 283, 372, 321, 379, 987]\n",
    "\n",
    "\n",
    "t3 =  [6, 7, 981, 80, 40, 949, 94, 436, 22, 41, 7512, 21, 49, 57, 21, 813, 79, 40, 52, 95, 77, 8, \n",
    "      68, 1, 61, 79, 99, 34, 81, 81, 66, 81, 870, 74, 83, 22, 700, 26, 400, 92, 58, 317, 23, 790, 33, 28, \n",
    "      72, 21, 79, .20]\n",
    "print(len(t1), len(t2), len(t3))\n",
    "\n",
    "# df1.loc[:,\"test1\"] , df1.loc[:,\"test2\"], df1.loc[:,\"test3\"] = t1, t2, t3\n",
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = remove_outlier(df1)\n",
    "# df1.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all categorical columns only\n",
    "# creating dummy variables for categorical variables\n",
    "\n",
    "# subset all categorical variables\n",
    "cars_categorical = X.select_dtypes(include=['object'])\n",
    "cars_categorical.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_categorical_drop.columns.to_list()\n",
    "or \n",
    "list(df2_categorical_drop.columns)\n",
    "or\n",
    "list(df2_categorical_drop.iloc[:,0:].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5, 'you': 6, 'am': 7, 'running': 8, 'with': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat',\n",
    "    'You love my dog!',\n",
    "    \"I am running with dog\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 1)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeking only the numeric features from the data or selecting only categorical column\n",
    "numeric_features = df2.select_dtypes(include = [np.number] or [\"object\"] or [np.float])\n",
    "\n",
    "df['ExterQual'] = df.ExterQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> Checking : How much Missing values present in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_miss_value(dataset):\n",
    "    higher_miss_value_column = []\n",
    "    miss_threshold_value = 50\n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        if dataset[i].isna().sum() > 1: \n",
    "            perectange_val = (dataset[i].isna().sum() / len(dataset)) * 100\n",
    "            print(\"Column-> \" , i, \", total no of missing value : \",dataset[i].isna().sum() , \" & :         \", round(perectange_val,2) ,\" %\")\n",
    "                \n",
    "            if(perectange_val > miss_threshold_value):\n",
    "                higher_miss_value_column.append(i)\n",
    "            \n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    if higher_miss_value_column:\n",
    "        print(\"Higher Missing values in Columns for Delete : \", higher_miss_value_column)\n",
    "    else:\n",
    "        print(\"There are no Higher Column Missing values in Dataset\")\n",
    "        \n",
    "\n",
    "def check_cloumn_details_type_categorical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            \n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "\n",
    "def check_cloumn_details_type_numberical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"int\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "def check_cloumn_details_type_float(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"float\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "def visualize_categorical_values(dataset):\n",
    "    no_of_columns = 4\n",
    "    no_of_rows = 4\n",
    "    \n",
    "    columns_object_type = [i for i in dataset.columns  if dataset[i].dtype == \"object\"]\n",
    "    total_rows = (len(columns_object_type) // no_of_rows ) + 1\n",
    "    \n",
    "    f, axes = plt.subplots(total_rows, no_of_columns, figsize=(18,24))\n",
    "\n",
    "    for ind, val in enumerate(columns_object_type):\n",
    "        sns.countplot(df[val] , ax = axes[ind // no_of_rows , ind %no_of_columns ])\n",
    "    plt.show()   \n",
    "    \n",
    "def check_skewness_numerical(dataset):\n",
    "    #analysing the distribution of sale price\n",
    "    print('skew is', dataset.SalePrice.skew())   \n",
    "    plt.hist(dataset['SalePrice'], color= 'b')\n",
    "\n",
    "    plt.title('Distribution of sales price of houses', fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel('sales price', fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def skewness_after_log_transform(dataset):\n",
    "    #log transforming sale price to transform it into gaussian distribution\n",
    "    target = np.log(df2.SalePrice)\n",
    "    print('skew is', target.skew())\n",
    "    plt.hist(target, color= 'b')\n",
    "\n",
    "    plt.title('Distribution of sales price of houses', fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel('sales price', fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Since pairplots for all numeric values together are not clear we can make groups ,do plot with price & analyse\n",
    "\n",
    "def pair_plot(list_4_numberical_values):\n",
    "    sns.pairplot(df2, x_vars= list_4_numberical_values, y_vars='SalePrice',size=4, kind='scatter')\n",
    "    plt.show()\n",
    "    \n",
    "def get_column_integer_float_list(dataset):\n",
    "    numberical_int_columns = []\n",
    "    for i in df2.columns:\n",
    "        if df2[i].dtype == \"int\":\n",
    "            numberical_int_columns.append(i)\n",
    "        \n",
    "    numberical_float_columns = []\n",
    "    for i in df2.columns:\n",
    "        if df2[i].dtype == \"float\":\n",
    "            numberical_float_columns.append(i)\n",
    "            \n",
    "    return numberical_int_columns, numberical_float_columns\n",
    "\n",
    "# pair_plot(numberical_int_columns[0:3] or numberical_float_columns[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(dataset, columns_name):\n",
    "    list = []\n",
    "    for chk in columns_name:\n",
    "        \n",
    "#         plt.boxplot(dataset[chk]) # please with graph & it is optional\n",
    "        \n",
    "        Q1 = dataset[chk].quantile(.25)\n",
    "        Q3 = dataset[chk].quantile(.75)\n",
    "        IQR = Q3-Q1\n",
    "        dataset =  dataset[(dataset[chk] >= (Q1-(1.5*IQR))) & (dataset[chk] <= (Q3+(1.5*IQR)))] \n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def corr_metrix():\n",
    "    corr = df2.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap='RdYlGn')\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "\n",
    "def corr_2_more_visualize(dataset):\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20, 9))\n",
    "    sns.heatmap(corr.apply(lambda x : np.round(x,2)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,annot=True,cmap='RdYlGn', annot_kws={\"size\": 15})\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "def convet_categorical_numerical_use_get_dummy(dataset):\n",
    "    df2_categorical = dataset.select_dtypes(include =  [\"object\"] )\n",
    "    df_dummies = pd.get_dummies(df2_categorical,drop_first=True)\n",
    "    \n",
    "    # drop categorical variables \n",
    "    dataset = dataset.drop(columns=list(df2_categorical.columns), axis=1)\n",
    "    \n",
    "    # concat dummy variables with X\n",
    "    dataset = pd.concat([dataset, df_dummies], axis=1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def reg_evaluation(y_actual, y_pred, data_type):\n",
    "    print(\"Model Evaluation Dataset Type is  : \", data_type)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Accuracy  :  \", r2_score(y_actual, y_pred))\n",
    "    print(\"MAE       :  \", mean_absolute_error(y_actual, y_pred))\n",
    "#     print(\"MSLE      :  \", mean_squared_log_error(y_actual, y_pred))\n",
    "    print(\"MSE       :  \", mean_squared_error(y_actual, y_pred))\n",
    "    print(\"RMSE      :  \", np.sqrt(mean_squared_error(y_actual, y_pred)))\n",
    "    \n",
    "def linear_regression_train_test():\n",
    "    #Linear regression with L2 regularization\n",
    "    for i in range(-2, 3):\n",
    "        alpha = 10**i\n",
    "        rm = Ridge(alpha = alpha)\n",
    "        ridge_model = rm.fit(X_train, y_train)\n",
    "        preds_ridge = ridge_model.predict(X_test)\n",
    "    \n",
    "        plt.scatter(preds_ridge, y_test, alpha= 0.75, c= 'b')\n",
    "        plt.xlabel('Predicted price')\n",
    "        plt.ylabel('Actual price')\n",
    "        plt.title('Ridge redularization with alpha {}'.format(alpha))\n",
    "        overlay = 'R square: {} \\nRMSE: {}'.format(ridge_model.score(X_test, y_test), mean_squared_error(y_test, preds_ridge))\n",
    "        plt.annotate(s = overlay, xy = (12.1, 10.6), size = 'x-large')\n",
    "        plt.show()\n",
    "        \n",
    "def actual_predict_visualization(actual_values, predict_values):\n",
    "    plt.scatter(actual_values, predict_values, alpha= 0.75, color = 'b')\n",
    "\n",
    "    plt.xlabel('Predicted price')\n",
    "    plt.ylabel('Actual price')\n",
    "    plt.title('Regression Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.25 , random_state = i)\n",
    "            model.fit(x_train,y_train)\n",
    "            pred_test = model.predict(x_test)\n",
    "            row = [names[j],i,r2_score (y_test,pred_test)]\n",
    "            rows.append(row)\n",
    "    models_df = pd.DataFrame(rows)   \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def mean_absolute_percentage_error(y_true, y_pred) :\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return np.mean(np.abs( (y_true - y_pred) / 100) ) * 100\n",
    "\n",
    "\n",
    "def root_mean_sequare_error(y_true, y_pred) : \n",
    "    mse = mean_squared_error(y_true,  y_pred)  \n",
    "    return np.sqrt(mse)\n",
    "   \n",
    "\n",
    "rows=[]\n",
    "\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            \n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.30 , random_state = i)\n",
    "            \n",
    "            model.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred_train = model.predict(x_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            train_acc = r2_score(y_train, y_pred_train)\n",
    "            train_acc = round(train_acc, 2) * 100\n",
    "            \n",
    "            test_acc = r2_score(y_test, y_pred)\n",
    "            test_acc = round(test_acc, 2) * 100\n",
    "            \n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "            mape = round(mape, 2)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, y_pred)   \n",
    "            mae = round(mae, 2)\n",
    "            \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse = round(mse, 2)\n",
    "            \n",
    "            rmse = root_mean_sequare_error(y_test, y_pred)\n",
    "            rmse = round(rmse, 2)\n",
    "\n",
    "            row = [names[j],   i,   train_acc, test_acc,  mae,    mse]\n",
    "    \n",
    "            rows.append(row)\n",
    "            \n",
    "    models_df = pd.DataFrame(rows) \n",
    "    \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    \n",
    "names_regression = [ \"Lasso\", \"Ridge\"]\n",
    "algorithms = [ Lasso(), Ridge(alpha=ridge_alpha)]\n",
    "\n",
    "columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\",   \"MAE\",   \"MSE\"]\n",
    "\n",
    "random_state_list_up_to_10 = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "addRandomStateForAlgorithm(X,y,names_regression,algorithms,columns_name,random_state_list_up_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
