{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor # why?\n",
    "\n",
    "# import gym # why use gym ?????\n",
    "\n",
    "from scipy import stats as s\n",
    "from random import randint\n",
    "from re import search\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "from functools import reduce\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "\n",
    "# import pprint\n",
    "from pprint import pprint \n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "#ProfileReport(df) # get all details like : min, max, correlation, else\n",
    "\n",
    "# %matplotlib notebook vs %matplotlib inline #vvi : %matplotlib notebook\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "\n",
    "# df=pd.read_csv(\"CarPrice_Assignment.csv\",encoding = \"ISO-8859-1\",low_memory=False)\n",
    "\n",
    " #************ titanic_df.profile_report() #VVI \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from timeit import timeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > Common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from collections import Counter , defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from pandas import Series as s , DataFrame as df\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt, rcParams as rc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rc[\"figure.figsize\"] = 10,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor , XGBRFRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='orange' > Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "#Modle Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, recall_score, precision_score, explained_variance_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='blue' > HighLevel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.combine import SMOTETomek # over sampling method 1\n",
    "\n",
    "## RandomOverSampler to handle imbalanced data\n",
    "from imblearn.over_sampling import RandomOverSampler # over sampling method 2\n",
    "\n",
    "\n",
    "#Shuffle the dataframe\n",
    "# from sklearn.utils import shuffle # df1 = shuffle(df).reset_index(drop = True)\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm \n",
    "\n",
    "\n",
    "from pickle import dump, load\n",
    "from joblib import dump, load\n",
    "\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from iteration_utilities import duplicates, unique_everseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='yellow' > NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Set\n",
    "telecom_df =  pd.read_csv('telecom_churn_data.csv')\n",
    "\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get only duplicate value :  [1, 1, 2, 2]\n",
      "all unique value         :  [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "l1 = [1,1,2,1,2,3,4,2]\n",
    "def get_only_duplicate_list_value(l):\n",
    "    return list(duplicates(l))\n",
    "\n",
    "def get_only_unique_list_value(l):\n",
    "    return list(unique_everseen(l))\n",
    "\n",
    "\n",
    "print(\"get only duplicate value : \", get_only_duplicate_list_value(l1))\n",
    "\n",
    "\n",
    "print(\"all unique value         : \", get_only_unique_list_value(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute for missing value(Numberical : mean, categorical :mode(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0] if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "df6 = DataFrameImputer().fit_transform(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "def remove_outlier(dataframe):\n",
    "    low = .05\n",
    "    high = .95\n",
    "    quant_df = dataframe.quantile([low, high])\n",
    "    for name in list(dataframe.columns):\n",
    "        if is_numeric_dtype(dataframe[name]):\n",
    "            dataframe = dataframe[(dataframe[name] > quant_df.loc[low, name]) & (dataframe[name] < quant_df.loc[high, name])]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_col_name_df(dataset): #testing has been pending\n",
    "    return dataset.select_dtypes(include=['object']) #get all categorical columns only\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat',\n",
    "    'You love my dog!',\n",
    "    \"I am running with dog\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 1)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeking only the numeric features from the data or selecting only categorical column\n",
    "numeric_features = df2.select_dtypes(include = [np.number] or [\"object\"] or [np.float])\n",
    "\n",
    "df['ExterQual'] = df.ExterQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> Checking : How much Missing values present in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def understanding_dataset(dataset):\n",
    "    print(f\"Shape: {dataset.shape}\")\n",
    "    print(f\"Total Missing Value in Dataset: {dataset.isna().sum().sum()}\")\n",
    "    \n",
    "    for column in dataset.columns:\n",
    "        print(f\"===============Column: {column} ==============\")\n",
    "        print(f\"Number of unique values: {dataset[column].nunique()}\")\n",
    "        print(f\"Max: {dataset[column].max()}\")\n",
    "        print(f\"Min: {dataset[column].min()}\")\n",
    "        \n",
    "        if(dataset[column].isna().any()):\n",
    "            print(f\"Missing Value: {round((data[[column]].isna().sum() / len(data) ) * 100 , 2)}\")\n",
    "    \n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def get_percentage_miss_value(dataset):\n",
    "    higher_miss_value_column = []\n",
    "    miss_threshold_value = 50\n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        if dataset[i].isna().sum() > 1: \n",
    "            perectange_val = (dataset[i].isna().sum() / len(dataset)) * 100\n",
    "            print(\"Column-> \" , i, \", total no of missing value : \",dataset[i].isna().sum() , \" & :         \", round(perectange_val,2) ,\" %\")\n",
    "                \n",
    "            if(perectange_val > miss_threshold_value):\n",
    "                higher_miss_value_column.append(i)\n",
    "            \n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    if higher_miss_value_column:\n",
    "        print(\"Higher Missing values in Columns Name : \", higher_miss_value_column)\n",
    "    else:\n",
    "        print(\"There are no Higher Column Missing values in Dataset\")\n",
    "        \n",
    "\n",
    "def check_cloumn_details_type_categorical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            \n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "\n",
    "def check_cloumn_details_type_numberical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"int\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "def check_cloumn_details_type_float(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"float\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "def convet_categorical_numerical_use_get_dummy(dataset):\n",
    "    df2_categorical = dataset.select_dtypes(include =  [\"object\"] )\n",
    "    df_dummies = pd.get_dummies(df2_categorical,drop_first=True)\n",
    "    \n",
    "    # drop categorical variables \n",
    "    dataset = dataset.drop(columns=list(df2_categorical.columns), axis=1)\n",
    "    \n",
    "    # concat dummy variables with X\n",
    "    dataset = pd.concat([dataset, df_dummies], axis=1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def get_column_integer_float_list(dataset):\n",
    "    numberical_int_columns = []\n",
    "    for i in df2.columns:\n",
    "        if df2[i].dtype == \"int\":\n",
    "            numberical_int_columns.append(i)\n",
    "        \n",
    "    numberical_float_columns = []\n",
    "    for i in df2.columns:\n",
    "        if df2[i].dtype == \"float\":\n",
    "            numberical_float_columns.append(i)\n",
    "            \n",
    "    return numberical_int_columns, numberical_float_columns\n",
    "\n",
    "# pair_plot(numberical_int_columns[0:3] or numberical_float_columns[0:3])\n",
    "\n",
    "\n",
    "\n",
    "# We one-hot encode the categorical features\n",
    "def one_hot_encoding(rides):\n",
    "    dummy_fields = ['season', 'weather', 'month', 'hour', 'weekday']\n",
    "    for each in dummy_fields:\n",
    "        dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "        rides = pd.concat([rides, dummies], axis=1)\n",
    "    return rides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(dataset, columns_name):\n",
    "    for chk in columns_name:\n",
    "        \n",
    "#         plt.boxplot(dataset[chk]) # please with graph & it is optional\n",
    "        \n",
    "        Q1 = dataset[chk].quantile(.25)\n",
    "        Q3 = dataset[chk].quantile(.75)\n",
    "        IQR = Q3-Q1\n",
    "        dataset =  dataset[(dataset[chk] >= (Q1-(1.5*IQR))) & (dataset[chk] <= (Q3+(1.5*IQR)))] \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardscaler_preprocessing(dataset_train, dataset_test, num_col):\n",
    "    scaler = StandardScaler()\n",
    "   \n",
    "    dataset_train[num_col] = scaler.fit_transform(dataset_train[num_col])\n",
    "\n",
    "    dataset_test[num_col] = scaler.transform(dataset_test[num_col])\n",
    "    \n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "\n",
    "\n",
    "#Label encoding\n",
    "def convert_to_numerical_label_encoding(dataset):\n",
    "    enc = LabelEncoder()\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            dataset[i] = enc.fit_transform(dataset[i])\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "#function for converting categoric to num codes\n",
    "#Changing Categorical colum values to numeric codes¶\n",
    "\n",
    "def cat_to_num(dataset):\n",
    "    for i in range(0, dataset.shape[1]):\n",
    "        #print(i)\n",
    "        if(dataset.iloc[:,i].dtypes == 'object'):\n",
    "            dataset.iloc[:,i] = pd.Categorical(dataset.iloc[:,i])\n",
    "            dataset.iloc[:,i] = dataset.iloc[:,i].cat.codes\n",
    "            dataset.iloc[:,i] = dataset.iloc[:,i].astype('object')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train = cat_to_num(train)\n",
    "test = cat_to_num(test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cab_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "cabs =  cab_encoder.fit_transform(df[\"Type_of_Cab\"].values.reshape(-1,1)).todense()\n",
    "\n",
    "lifestyle_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "life = lifestyle_encoder.fit_transform(df[\"Confidence_Life_Style_Index\"].values.reshape(-1,1)).todense()\n",
    "\n",
    "dest_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "dest = dest_encoder.fit_transform(df[\"Destination_Type\"].values.reshape(-1,1)).todense()\n",
    "\n",
    "gender_encoder = OneHotEncoder(dtype=np.uint8)\n",
    "gender = gender_encoder.fit_transform(df[\"Gender\"].values.reshape(-1,1)).todense()\n",
    "\n",
    "X = np.array(np.hstack((X,cabs,life,dest,gender)))\n",
    "print (np.array(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visulazing the distibution of the data for every feature\n",
    "def visualize_hist(dataset):\n",
    "    dataset.hist(edgecolor='black', linewidth=1.2, figsize=(20, 20));\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_histogram(dataset):\n",
    "    # plot histogram\n",
    "    plt.figure(figsize=(25, 9))  # figure size in ratio 16:9\n",
    "    features = dataset.columns  # list of columns name\n",
    "    for i, j in enumerate(features):\n",
    "        plt.subplot(3, 3, i + 1)  # create subplot for histogram\n",
    "        plt.title(\"Histogram of {}\".format(j), fontsize=15)  # title of histogram\n",
    "\n",
    "        bins = len(dataset[j].unique())  # bins for histogram\n",
    "        plt.hist(dataset[j], bins=bins, rwidth=0.8, edgecolor=\"y\", linewidth=2, )  # plot histogram\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)  # space between horixontal axes (subplots)\n",
    "    \n",
    "def corr_metrix(dataset):\n",
    "    corr = dataset.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap='RdYlGn')\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "def corr_2_more_visualize(dataset):\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20, 9))\n",
    "    sns.heatmap(corr.apply(lambda x : np.round(x,2)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,annot=True,cmap='RdYlGn', annot_kws={\"size\": 15})\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def linear_regression_train_test(X_train_val, y_train_val, X_test_val, y_test_val):\n",
    "    #Linear regression with L2 regularization\n",
    "    for i in range(-2, 3):\n",
    "        alpha = 10**i\n",
    "        rm = Ridge(alpha = alpha)\n",
    "        ridge_model = rm.fit(X_train_val, y_train_val)\n",
    "        preds_ridge = ridge_model.predict(X_test_val)\n",
    "    \n",
    "        plt.scatter(preds_ridge, y_test, alpha= 0.75, c= 'b')\n",
    "        plt.xlabel('Predicted price')\n",
    "        plt.ylabel('Actual price')\n",
    "        plt.title('Ridge redularization with alpha {}'.format(alpha))\n",
    "        \n",
    "        overlay = 'R square: {} \\nRMSE: {}'.format(ridge_model.score(X_test_val, y_test_val), \n",
    "                                                   mean_squared_error(y_test_val, preds_ridge))\n",
    "        plt.annotate(s = overlay, xy = (12.1, 10.6), size = 'x-large')\n",
    "        plt.show()\n",
    "        \n",
    "def actual_predict_visualization(actual_values, predict_values):\n",
    "    plt.scatter(actual_values, predict_values, alpha= 0.75, color = 'b')\n",
    "\n",
    "    plt.xlabel('Predicted price')\n",
    "    plt.ylabel('Actual price')\n",
    "    plt.title('Regression Model')\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_original_predict_test(X_val, Y_val, default = \"Test\"):\n",
    "    print(\"Dataset type  : \\n\" ,default)\n",
    "    plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "    plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.xlabel(\"X axis\", color = \"red\")\n",
    "    plt.ylabel(\"Y axis\", color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_categorical_values(dataset):\n",
    "    no_of_columns = 4\n",
    "    no_of_rows = 4\n",
    "    \n",
    "    columns_object_type = [i for i in dataset.columns  if dataset[i].dtype == \"object\"]\n",
    "    total_rows = (len(columns_object_type) // no_of_rows ) + 1\n",
    "    \n",
    "    f, axes = plt.subplots(total_rows, no_of_columns, figsize=(18,24))\n",
    "\n",
    "    for ind, val in enumerate(columns_object_type):\n",
    "        sns.countplot(df[val] , ax = axes[ind // no_of_rows , ind %no_of_columns ])\n",
    "    plt.show()   \n",
    "    \n",
    "sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag')\n",
    "\n",
    "def visualize_pairplot_target(dataset, numberical_col_list , target_val):\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(data = dataset[numberical_col_list],hue = target_val)\n",
    "    \n",
    "    #     sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag') \n",
    "    #check for classification\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_numberical_values(dataset): #takes time\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(dataset)\n",
    "    plt.show()\n",
    "# visualize_numberical_values(df)\n",
    "\n",
    "# Since pairplots for all numeric values together are not clear we can make groups ,do plot with price & analyse\n",
    "\n",
    "def pair_plot(dataset, numberical_col_list , target_val):\n",
    "    sns.pairplot(dataset, x_vars= numberical_col_list, y_vars = target_val, size=4, kind='scatter')\n",
    "    plt.show()\n",
    "    \n",
    "def check_skewness_numerical(dataset, target):\n",
    "    #analysing the distribution of sale price\n",
    "    print('skew is', dataset[target].skew())   \n",
    "    plt.hist(dataset[target], color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target, fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def skewness_after_log_transform(dataset , target):\n",
    "    #log transforming sale price to transform it into gaussian distribution\n",
    "    target1 = np.log(dataset.target)\n",
    "    print('skew is', target1.skew())\n",
    "    plt.hist(target, color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target , fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# create plotting functions\n",
    "def data_type(variable):\n",
    "    if variable.dtype == np.int64 or variable.dtype == np.float64:\n",
    "        return 'numerical'\n",
    "    elif variable.dtype == 'category':\n",
    "        return 'categorical'\n",
    "    \n",
    "def visualization_univariate(feature_name, stats=True):\n",
    "    \n",
    "    if data_type(feature_name) == 'numerical':\n",
    "        sns.distplot(feature_name)\n",
    "        plt.show()\n",
    "        if stats == True:\n",
    "            print(feature_name.describe())\n",
    "    \n",
    "    elif data_type(feature_name) == 'categorical':\n",
    "        sns.countplot(feature_name)\n",
    "        plt.show()\n",
    "        if stats == True:\n",
    "            print(feature_name.value_counts())\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n",
    "        \n",
    "def visualize_bivariate(var1, var2):\n",
    "    if data_type(var1) == 'numerical' and data_type(var2) == 'numerical':\n",
    "        sns.regplot(var1, var2)\n",
    "    elif (data_type(var1) == 'categorical' and data_type(var2) == 'numerical') \n",
    "        or (data_type(var1) == 'numerical' and data_type(var2) == 'categorical'):        \n",
    "        sns.boxplot(var1, var2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boxplot(dataset, target, feature_var = \" \"):\n",
    "    cont_cols = [col for col in dataset.columns if col not in [target, feature_var]]\n",
    "        \n",
    "        for col in cont_cols:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.boxplot(y=col, data=dataset)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def visualize_barplot(dataset, target, feature_var = \" \"):\n",
    "    cont_cols = [col for col in dataset.columns if col not in [target, feature_var]]\n",
    "        \n",
    "        for col in cont_cols:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.barplot(x = target, y=col, data=dataset)\n",
    "        plt.show()\n",
    "\n",
    "#Groupby --> size to represent ---> unstack the category\n",
    "#train.groupby([\"state\", \"Churn\"]).size().unstack(level=-1).head()\n",
    "\n",
    "#Relationational bar graph for checking data distribution with respect to target variable\n",
    "def diff_bar(x,y):\n",
    "    \n",
    "    train.groupby([x,y]).size().unstack(level=-1).plot(kind='bar', figsize=(35,10))\n",
    "    plt.xlabel(x,fontsize= 25)\n",
    "    plt.ylabel('count',fontsize= 25)\n",
    "    plt.legend(loc=0,fontsize= 25)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.title(\"{X} Vs {Y}\".format(X=x,Y=y),fontsize = 40)\n",
    "    plt.show()\n",
    "    \n",
    "#area_code Wise Churning of customer\n",
    "diff_bar('area code','Churn')\n",
    "\n",
    "\n",
    "#Scatter plot function\n",
    "def diff_scattr(x1,x2):\n",
    "    fig = plt.figure()\n",
    "    fig = sns.lmplot(x,y, data=train,fit_reg=False)\n",
    "    plt.xlabel(x,fontsize= 14)\n",
    "    plt.ylabel(y,fontsize= 14)\n",
    "    plt.xticks(fontsize=10, rotation=90)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.title(\"{X} and {Y} Scatter Plot\".format(X=x1,Y=x2),fontsize = 16)\n",
    "    #fig.savefig(\"{X}_and_{Y}_Scatter_Plot..png\".format(X=x,Y=y))\n",
    "    plt.show()\n",
    "    \n",
    "#Total eve charge and Total eve Minute\n",
    "diff_scattr('total eve charge','total eve minutes') #x1 : input1 , x2: input2\n",
    "\n",
    "# #Histogram breaks down by target variable\n",
    "def plot_histogram_target(feature_col , target):\n",
    "    plt.hist(list(feature_col[target == 1]),color='green',label='True',bins='auto')\n",
    "    plt.hist(list(feature_col[target == 0]),color='grey', alpha = 0.7, label='False',bins='auto')\n",
    "    plt.title(\"Histogram of {var} breakdown by {Y}\".format(var = feature_col.name, Y = target.name))\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"Histogram of {var} breakdown by {Y}.png\".format(var = feature_col.name, Y = target.name))\n",
    "    plt.show()\n",
    "\n",
    "for i in df_numberical_type:\n",
    "    #print(i)\n",
    "    plot_histogram_target(df[i] , df[\"target\"])\n",
    "    \n",
    "    \n",
    "# Univariate Analysis on Numerical Variables¶\n",
    "\n",
    "def visualize_plot_box(dataset, numeric_variable):\n",
    "    sns.boxplot(y=dataset[numeric_variable])\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim(5, 50)\n",
    "    plt.title(\"Distribution of \"+ numeric_variable)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "for numeric_variable in df._get_numeric_data():\n",
    "    visualize_plot_box(df, numeric_variable)\n",
    "\n",
    "def plot_continuous_variable_boxPlot(dataset, feature_col, target):\n",
    "    \n",
    "    '''Function plots a graphical Boxplot for the passed dataframe.\n",
    "\n",
    "        Input:\n",
    "            param: name of the parameter for which Box is plotted.\n",
    "            df: pandas DataFrame'''\n",
    "    \n",
    "    class_val_0=dataset[dataset.target == 0]\n",
    "    class_val_1=dataset[dataset.target  == 1]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10)) \n",
    "    plt.subplot(1,2,1)\n",
    "    sns.boxplot(y=class_val_0[feature_col])\n",
    "    plt.title(feature_col +' distribution for Not Churned ',fontsize=20)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(y=class_val_0[feature_col])\n",
    "    plt.title(feature_col +' distribution for Churned ',fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "aon_df = df[['churn','aon_years']]\n",
    "plot_continuous_variable_boxPlot(aon_df,'aon_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,3,figsize=(15,5))\n",
    "sns.distplot(df.Var1,ax=axes[0])\n",
    "sns.distplot(df.Var2,ax=axes[1])\n",
    "sns.distplot(df.Var3,ax=axes[2])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "colors = [\"#228B22\", \"#FF6347\"]\n",
    "\n",
    "labels =\"No Churn\", \"Churn\"\n",
    "plt.suptitle('Information on Churn', fontsize=20)\n",
    "\n",
    "telecom_df[\"churn\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, \n",
    "                                    colors=colors, labels=labels, fontsize=12, startangle=70)\n",
    "ax[0].set_ylabel('% of Condition of Churn', fontsize=14)\n",
    "\n",
    "palette = [\"#228B22\", \"#FF6347\"]\n",
    "\n",
    "\n",
    "sns.barplot(x=\"monthly_2g_8\", y=\"churn\", hue=\"churn\", data=telecom_df, palette=palette, \n",
    "            estimator=lambda x: len(x) / len(telecom_df) * 100)\n",
    "ax[1].set(ylabel=\"(%)\")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "df.Gender.value_counts(1).plot.bar() # give the % of highest particiate vaule in column value_counts(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.25 , random_state = i)\n",
    "            model.fit(x_train,y_train)\n",
    "            pred_test = model.predict(x_test)\n",
    "            row = [names[j],i,r2_score (y_test,pred_test)]\n",
    "            rows.append(row)\n",
    "    models_df = pd.DataFrame(rows)   \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    \n",
    "    \n",
    "def mean_absolute_percentage_error(y_true, y_pred) :\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return np.mean(np.abs( (y_true - y_pred) / 100) ) * 100\n",
    "\n",
    "\n",
    "def root_mean_sequare_error(y_true, y_pred) : \n",
    "    mse = mean_squared_error(y_true,  y_pred)  \n",
    "    return np.sqrt(mse)\n",
    "   \n",
    "\n",
    "rows=[]\n",
    "\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            \n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.30 , random_state = i)\n",
    "            \n",
    "            model.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred_train = model.predict(x_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            train_acc = r2_score(y_train, y_pred_train)\n",
    "            train_acc = round(train_acc, 2) * 100\n",
    "            \n",
    "            test_acc = r2_score(y_test, y_pred)\n",
    "            test_acc = round(test_acc, 2) * 100\n",
    "            \n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "            mape = round(mape, 2)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, y_pred)   \n",
    "            mae = round(mae, 2)\n",
    "            \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse = round(mse, 2)\n",
    "            \n",
    "            rmse = root_mean_sequare_error(y_test, y_pred)\n",
    "            rmse = round(rmse, 2)\n",
    "\n",
    "            row = [names[j],   i,   train_acc, test_acc,  mae,    mse]\n",
    "    \n",
    "            rows.append(row)\n",
    "            \n",
    "    models_df = pd.DataFrame(rows) \n",
    "    \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    \n",
    "names_regression = [ \"Lasso\", \"Ridge\"]\n",
    "algorithms = [ Lasso(), Ridge(alpha=ridge_alpha)]\n",
    "\n",
    "columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\",   \"MAE\",   \"MSE\"]\n",
    "\n",
    "random_state_list_up_to_10 = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "addRandomStateForAlgorithm(X,y,names_regression,algorithms,columns_name,random_state_list_up_to_10)\n",
    "\n",
    "\n",
    "def get_accuracy(y_actual, y_pred, data_type = \"Train\"):\n",
    "    print(\"Model Evaluation Dataset Type is  : \", data_type)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Accuracy  :  \", r2_score(y_actual, y_pred))\n",
    "    print(\"MAE       :  \", mean_absolute_error(y_actual, y_pred))\n",
    "    print(\"MSLE      :  \", mean_squared_log_error(y_actual, y_pred))\n",
    "    print(\"MSE       :  \", mean_squared_error(y_actual, y_pred))\n",
    "    print(\"RMSE      :  \", np.sqrt(mean_squared_error(y_actual, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            \n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.30 , random_state = i)\n",
    "            \n",
    "            model.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred_train = model.predict(x_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            train_acc = accuracy_score(y_train, y_pred_train)\n",
    "            train_acc = round(train_acc, 4) * 100\n",
    "            \n",
    "            test_acc = accuracy_score(y_test, y_pred)\n",
    "            test_acc = round(test_acc, 4) * 100\n",
    "            \n",
    "            roc_auc_score_acc = roc_auc_score(y_test, y_pred)\n",
    "            roc_auc_score_acc = round(roc_auc_score_acc, 4) * 100\n",
    "            \n",
    "            row = [names[j],   i,   train_acc, test_acc, roc_auc_score_acc]\n",
    "    \n",
    "            rows.append(row)\n",
    "            \n",
    "    models_df = pd.DataFrame(rows) \n",
    "    \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "names = [ \"LightGBM\", \"RF\", \"XGBoost\" , \"SVM\", \"LogisticRegression\", \"DTClassifier\", \"CatBoostClassifier\"]\n",
    "\n",
    "algorithms = [ LGBMClassifier(  ), RandomForestClassifier(), XGBClassifier(), SVC() ,\n",
    "              LogisticRegression(), DecisionTreeClassifier(), CatBoostClassifier()]\n",
    "\n",
    "\n",
    "columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\" , \"roc_auc_acc\"]\n",
    "\n",
    "random_state_list_up_to_3 = [1,2,3]\n",
    "\n",
    "addRandomStateForAlgorithm(X4,Y4,names,algorithms,columns_name,random_state_list_up_to_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > Imabalnced Dataset : Over Sampling(Majoruity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_imbalanced_dataset(dataset, target_col):\n",
    "    feature_columns = dataset.columns.tolist()\n",
    "    feature_columns = [c for c in feature_columns if c not in [target_col]]\n",
    "\n",
    "    X2_new = dataset[feature_columns]\n",
    "    Y2_new = dataset[target_col]\n",
    "\n",
    "    os =  RandomOverSampler(random_state=35)\n",
    "    X_feature_variables , y_output = os.fit_sample(X2_new, Y2_new)\n",
    "    \n",
    "    X_feature_variables[target_col] = y_output\n",
    "    \n",
    "    X_feature_variables = X_feature_variables.sample(frac = 1).reset_index(drop = True)\n",
    "    \n",
    "    return X_feature_variables\n",
    "\n",
    "# Counter(df2.target)\n",
    "# df3 = majority_imbalanced_dataset(df2, \"target\")\n",
    "# Counter(df3.target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, random_state=108)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = CatBoostClassifier(verbose=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test, y_test))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using VIF for multicollinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "pd.Series([variance_inflation_factor(X_train.values, j) for j in range( X_train.shape[1])],index=X_train.columns)\n",
    "\n",
    "#or\n",
    "\n",
    "def calculate_vif(X_train_val): # x : \n",
    "    thresh=10.0\n",
    "    output= X_train_val\n",
    "    k=X_train_val.shape[1]\n",
    "    \n",
    "    vif=[variance_inflation_factor(X_train_val.values,j) for j in range(X_train_val.shape[1])]\n",
    "    for i in range(1,k):#till k cz atleast one column would be kept even if its greater than 5\n",
    "        print('iteration no',i)\n",
    "        print(vif)\n",
    "        a=np.argmax(vif)\n",
    "        print('max vif is for variable no',a)\n",
    "        print(\" \")\n",
    "        if vif[a]<=thresh:\n",
    "            break\n",
    "        else:\n",
    "            output=output.drop(output.columns[a],axis=1)\n",
    "            vif=[variance_inflation_factor(output.values,j) for j in range(output.shape[1])]\n",
    "    return output\n",
    "\n",
    "X_vif=calculate_vif(X_train)\n",
    "\n",
    "X_train_dup=X_vif\n",
    "X_train_dup.columns\n",
    "\n",
    "X_test= X_test[X_train_dup.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plz check for regression also? check for train dataset also?\n",
    "def check_cross_validation_overfit(X_val, Y_val, classification_model):\n",
    "    #cv = use diff\n",
    "    cross_validation_accuracy = cross_val_score(estimator = classification_model, X = X_val, y = Y_val, cv = 2).mean()\n",
    "    \n",
    "    model_accuracy =  accuracy_score(X_val,   Y_val)\n",
    "    \n",
    "    print(\"checking overfit & underfit :  almost same\" )\n",
    "\n",
    "    print(\"Model Accuracy : \", model_accuracy, \" & cross validation \", cross_validation_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > XGBoost Classification with Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_param_test = {\n",
    "    \n",
    "    'gamma': [2, 5,7],\n",
    "    'max_depth': [3, 4,5],\n",
    "    'learning_rate': [0.05,0.07],\n",
    "    'n_estimators': [100,200],\n",
    "#     objective = ['binary:logistic',  'multi:softmax'],\n",
    "#     num_classes = [2, 3] # output : binary(2) or multi classification\n",
    "  \n",
    "}\n",
    "\n",
    "XGB_hyper_params = GridSearchCV(estimator = \n",
    "XGBClassifier(learning_rate =0.1,\n",
    "#               objective= 'binary:logistic',\n",
    "              objective = 'multi:softmax',\n",
    "                                num_classes =  3,\n",
    "              nthread=4,\n",
    "              seed=27), \n",
    "                                \n",
    "              param_grid = xg_param_test,\n",
    "              scoring= 'accuracy',\n",
    "              n_jobs=4,\n",
    "              iid=False,\n",
    "              verbose=10)\n",
    "\n",
    "XGB_hyper_params.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(XGB_hyper_params.best_params_)\n",
    "\n",
    "\n",
    "xgbclf=XGBClassifier(gamma= 7,learning_rate= 0.05, max_depth= 5,n_estimators= 200)\n",
    "xgbclf.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_final = XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=1000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'multi:softmax',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  num_classes=3,\n",
    "#  seed=27)\n",
    "\n",
    "\n",
    "\n",
    "model_final = XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)\n",
    "\n",
    "model_final = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "model_final.fit(X, Y)\n",
    "\n",
    "y_pred_final = model_final.predict(df5_test)\n",
    "\n",
    "\n",
    "#3rd solution\n",
    "params = {\"objective\": \"multi:softmax\",\"booster\": \"gbtree\", \"nthread\": 4, \"silent\": 1,\n",
    "                \"eta\": 0.08, \"max_depth\": 6, \"subsample\": 0.9, \"colsample_bytree\": 0.7,\n",
    "                \"min_child_weight\": 1, \"num_class\": 3,\n",
    "                \"seed\": 2016, \"tree_method\": \"exact\"}\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train, missing=np.nan)\n",
    "dtest = xgb.DMatrix(X_test, missing=np.nan)\n",
    "\n",
    "nrounds = 260\n",
    "watchlist = [(dtrain, 'train')]\n",
    "bst = xgb.train(params, dtrain, num_boost_round=nrounds, evals=watchlist, verbose_eval=20)\n",
    "test_preds = bst.predict(dtest)\n",
    "\n",
    "#4th\n",
    "params = {\"objective\": \"multi:softmax\",\"booster\": \"gbtree\", \"nthread\": 4, \"silent\": 1,\n",
    "                \"eta\": 0.08, \"max_depth\": 6, \"subsample\": 0.9, \"colsample_bytree\": 0.7,\n",
    "                \"min_child_weight\": 1, \"num_class\": 3,\n",
    "                \"seed\": 2016, \"tree_method\": \"exact\"}\n",
    "dtrain = xgb.DMatrix(X_train, y_train, missing=np.nan)\n",
    "dtest = xgb.DMatrix(X_test, mising=np.nan)\n",
    "\n",
    "nrounds = 260\n",
    "watchlist = [(dtrain, 'train')]\n",
    "bst = xgb.train(params, dtrain, num_boost_round=nrounds, evals=watchlist, verbose_eval=20)\n",
    "test_preds = bst.predict(dtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()\n",
    "\n",
    "\n",
    "\n",
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > LightBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-cacd6f5ea648>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-cacd6f5ea648>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    param_grid = lg_param_test,\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lg_param_test = {\n",
    "    \n",
    "    'gamma': [0.5, 0.25],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.07, 0.05],\n",
    "    'n_estimators': [200, 100]\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "lgb_model = LGBMClassifier(learning_rate =0.1, nthread=4,seed=27)\n",
    "\n",
    "LGB_hyper_params = GridSearchCV(estimator = lgb_model\n",
    "              param_grid = lg_param_test,\n",
    "              scoring= 'accuracy',\n",
    "              n_jobs=4,\n",
    "              iid=False,\n",
    "              verbose=10)\n",
    "\n",
    "LGB_hyper_params.fit(X,Y)\n",
    "\n",
    "\n",
    "print(LGB_hyper_params.best_params_)\n",
    "\n",
    "\n",
    "# lgbclf= LGBMClassifier(gamma= 0.5, learning_rate= 0.07,max_depth= 5, n_estimators= 200)\n",
    "# Default  objective='multi:softmax', num_classes=3\n",
    "\n",
    "#or\n",
    "lgbclf= LGBMClassifier(gamma= 0.5, learning_rate= 0.07,max_depth= 5, n_estimators= 200, \n",
    "                       objective='multi:softmax', num_classes=3)\n",
    "\n",
    "\n",
    "lgbclf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model = LGBMClassifier(subsample= 0.9,\n",
    " reg_lambda= 2.5,\n",
    " reg_alpha= 1,\n",
    " random_state= 108,\n",
    " objective= 'multiclass',\n",
    " n_estimators= 4000,\n",
    " min_split_gain= 0.5,\n",
    " min_data_in_leaf= 20,\n",
    " metric= 'multi_logloss',\n",
    " max_depth= 8,\n",
    " learning_rate= 0.01,\n",
    " colsample_bytree= 1,\n",
    " boosting_type= 'gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X ,Y , test_size = 0.05 , random_state = 10)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "y_pred_final = gbm.predict(df5_test, num_iteration=gbm.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > LightBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_param_test = {\n",
    "    'depth':[2, 3],\n",
    "    'learning_rate': [0.07, 0.05],\n",
    "    'n_estimators': [200, 100],\n",
    "    'loss_function': ['Logloss', 'CrossEntropy', 'MultiClass'],\n",
    "    'l2_leaf_reg':np.logspace(-25, -20, 3)\n",
    "  \n",
    "}\n",
    "\n",
    "CAT_hyper_params = GridSearchCV(estimator = \n",
    "CatBoostClassifier(learning_rate =0.1), \n",
    "              param_grid = cat_param_test,\n",
    "              scoring= 'accuracy',\n",
    "              n_jobs=4,\n",
    "                                \n",
    "              iid=False,\n",
    "              verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "CAT_hyper_params.fit(X,Y)\n",
    "\n",
    "print(CAT_hyper_params.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catclf= CatBoostClassifier(depth= 3,l2_leaf_reg= 1e-25,learning_rate= 0.07,loss_function= 'MultiClass',\n",
    "                           n_estimators= 200)\n",
    "\n",
    "catclf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_m = CatBoostClassifier(n_estimators=5000,random_state=1994,eval_metric='MultiClass',learning_rate=0.1, max_depth=5)\n",
    "\n",
    "cat_m.fit(X_train, y_train,eval_set=[(X_test, y_test)],early_stopping_rounds=200,erbose=200)\n",
    "\n",
    "y_pred = cat_m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver='randomized', random_state=42) \n",
    "# or\n",
    "# pca = PCA(n_components =54 ) # no of component 54\n",
    "\n",
    "#Doing the PCA on the train data\n",
    "pca.fit(X_train)\n",
    "\n",
    "\n",
    "pca.components_\n",
    "\n",
    "colnames = list(X.columns)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\n",
    "pcs_df.head()\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#final code for pca\n",
    "\n",
    "# Will take the most important 54 features\n",
    "\n",
    "pca_final = PCA(n_components =54 )\n",
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape\n",
    "\n",
    "#Applying selected components to the test data\n",
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape\n",
    "\n",
    "#graph\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca_final.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "learner_pca = LogisticRegression()\n",
    "learner_pca.fit(df_train_pca,y_train)\n",
    "\n",
    "y_pred = learner_pca.predict(X_test)\n",
    "accuracy(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = [1,2,45,55,5,4,4,4,4,4,4,5456,56,6,7,67]\n",
    "\n",
    "def max_occurrences_1a(seq=L):\n",
    "    \"dict iteritems\"\n",
    "    c = dict()\n",
    "    for item in seq:\n",
    "        c[item] = c.get(item, 0) + 1\n",
    "    return max(c.iteritems(), key=itemgetter(1))\n",
    "\n",
    "max_occurrences_1a(L1)\n",
    "\n",
    "def max_occurrences_3a(seq=L):\n",
    "    \"sort groupby generator expression\"\n",
    "    return max(((k, sum(1 for i in g)) for k, g in groupby(sorted(seq))), key=itemgetter(1))\n",
    "max_occurrences_3a(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    ">>> L = [1, 2, 45, 55, 5, 4, 4, 4, 4, 4, 4, 5456, 56, 6, 7, 67] \n",
    ">>> statistics.mode(L)\n",
    "\n",
    "l1 = [1,2,3,2,3,2,3]\n",
    "statistics.mode(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Key = 0, based on value = 1 and based on Ascending = False or Descending = True\n",
    "#Default based on value and ascending\n",
    "\n",
    "def reverse_dict(dict_val , key_value = 1, ascending_descending = False):\n",
    "    \n",
    "    val = sorted(dict_val.items(), key = lambda x: x[key_value] , reverse = ascending_descending)\n",
    "    \n",
    "    return dict(val)\n",
    "\n",
    "def no_of_item_dict(dict_val , no_of_item):\n",
    "    dict_len = len(dict_val)\n",
    "    \n",
    "    if(dict_len != 0 and dict_len != 0 and  no_of_item <= dict_len):\n",
    "        for ind, val in enumerate(dict_val):\n",
    "            if(ind < no_of_item):\n",
    "                print(val[0] , \" \", val[1])                \n",
    "    else:\n",
    "        print(\"Please enter the valid input\")\n",
    "\n",
    "\n",
    "marks = {\"Raka\" : 99, \"ananya\" : 90 ,'John':85, 'Alex':80, 'Richard': 87, \"rakesh\" : 97 , \"Trishala\" : 92}\n",
    "dic_sorted = reverse_dict(marks, 0, False)\n",
    "\n",
    "print(dic_sorted)\n",
    "\n",
    "no_of_item_dict(dic_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra VVI Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list() or list(df.columns) or list(df.iloc[:,0:].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE  : %f\\nMSE  : %f\\nMSLE : %f\\nRMSE : %F\"%(MAE, MSE, MSLE, RMSE)) # %f or %F\n",
    "\n",
    "df['Var1'].fillna(df['Var1'].mean(), inplace=True)\n",
    "df['Var1'] = np.log(df['Var1'])\n",
    "\n",
    "combine = train.append(test)\n",
    "\n",
    "df.Type_of_Cab.fillna(method='bfill',inplace=True)\n",
    "\n",
    "\n",
    "features = np.setdiff1d(train.columns, ['Trip_ID', 'Surge_Pricing_Type']) \n",
    "# means: features do not hv 'Trip_ID', 'Surge_Pricing_Type' columns\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Sat May 16 09:22:18 2020\n",
    "\n",
    "@author: I354298\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0,100,size=(10, 5)), columns=list('ABCDE'))\n",
    "df2[\"target\"] = [2,1,1,2,1,2,1,1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Checking Distribution of data\n",
    "\n",
    "#Checking distribution of data via pandas visualization\n",
    "train[col_name].hist(figsize=(20,20),color='g',alpha = 0.7)\n",
    "#plt.savefig('distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(compare,predicted)\n",
    "\n",
    "#Get all int columns\n",
    "high_value_cust.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "#\n",
    "var1_median = train.Var1.dropna().median()\n",
    "df['Var1'] = df['Var1'].fillna(var1_median)\n",
    "\n",
    "\n",
    "\n",
    "# 0 - not churn, 1 - churn\n",
    "churn_filtered['churn'] = churn_filtered.apply(lambda row: 1 if (row.total_calls_mou_9 == 0 and row.total_internet_mb_9 == 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "\n",
    "telecom_df.info(verbose = True) or telecom_df.info(verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
